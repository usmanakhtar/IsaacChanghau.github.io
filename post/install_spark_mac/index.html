<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="theme" content="hugo-academic">
  <meta name="generator" content="Hugo 0.41" />
  <meta name="author" content="Zhang Hao">

  
  
  
  
    
      
    
  
  <meta name="description" content="It is an introduction of Spark installation under localhost mode. Generally, Spark is available for multiple models: local, clustered&ndash;Spark Standalone, clustered&ndash;Spark on Apache Mesos and so forth, more details here: link.
Install Spark Since Spark requires Hadoop environment, so we need to install and configure Hadoop first. Here, I assume you already installed and configured Hadoop environment successfully. After that, we need to install Scala (&gt;2.9.3 version). First, go to Scala official website and download the newest version of Scala, then unzip and move it to /usr/local/:">

  
  <link rel="alternate" hreflang="en-us" href="https://isaacchanghau.github.io/post/install_spark_mac/">

  


  

  
  
  <meta name="theme-color" content="#3f51b5">
  
  
  
  
    
  
  
    
    
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">
    
  
  
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha512-6MXa8B6uaO18Hid6blRMetEIoPqHf7Ux1tnyIQdpt9qI5OACx7C+O3IVTr98vwGnlcg0LOLa02i9Y1HpVhlfiw==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.1/css/academicons.min.css" integrity="sha512-NThgw3XKQ1absAahW6to7Ey42uycrVvfNfyjqcFNgCmOCQ5AR4AO0SiXrN+8ZtYeappp56lk1WtvjVmEa+VR6A==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha512-SfTiTlX6kk+qitfevl/7LibUOeJWlt9rbyDn92a1DqWOw9vWG2MFoays0sgObmWazO5BQPiFucnnEAjpAB+/Sw==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">
  
  
  
  
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Playfair&#43;Display:400,700%7cFauna&#43;One">
  
  <link rel="stylesheet" href="/styles.css">
  

  

  
  <link rel="alternate" href="https://isaacchanghau.github.io/index.xml" type="application/rss+xml" title="Isaac Changhau">
  <link rel="feed" href="https://isaacchanghau.github.io/index.xml" type="application/rss+xml" title="Isaac Changhau">
  

  <link rel="manifest" href="/site.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="https://isaacchanghau.github.io/post/install_spark_mac/">

  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="twitter:site" content="@https://twitter.com/IsaacChanghau">
  <meta property="twitter:creator" content="@https://twitter.com/IsaacChanghau">
  
  <meta property="og:site_name" content="Isaac Changhau">
  <meta property="og:url" content="https://isaacchanghau.github.io/post/install_spark_mac/">
  <meta property="og:title" content="Spark Installation on Mac OS X | Isaac Changhau">
  <meta property="og:description" content="It is an introduction of Spark installation under localhost mode. Generally, Spark is available for multiple models: local, clustered&ndash;Spark Standalone, clustered&ndash;Spark on Apache Mesos and so forth, more details here: link.
Install Spark Since Spark requires Hadoop environment, so we need to install and configure Hadoop first. Here, I assume you already installed and configured Hadoop environment successfully. After that, we need to install Scala (&gt;2.9.3 version). First, go to Scala official website and download the newest version of Scala, then unzip and move it to /usr/local/:">
  <meta property="og:locale" content="en-us">
  
  <meta property="article:published_time" content="2017-06-28T00:00:00&#43;08:00">
  
  <meta property="article:modified_time" content="2017-06-28T00:00:00&#43;08:00">
  

  

  <title>Spark Installation on Mac OS X | Isaac Changhau</title>

</head>
<body id="top" data-spy="scroll" data-target="#toc" data-offset="71" >

<nav class="navbar navbar-default navbar-fixed-top" id="navbar-main">
  <div class="container">

    
    <div class="navbar-header">
      
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse"
              data-target=".navbar-collapse" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      
      <a class="navbar-brand" href="/">Isaac Changhau</a>
    </div>

    
    <div class="collapse navbar-collapse">

      
      
      <ul class="nav navbar-nav navbar-right">
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#about">
            
            <span>Home</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#projects">
            
            <span>Projects</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#posts">
            
            <span>Posts</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#tags">
            
            <span>Tags</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#publications">
            
            <span>Publications</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#achievements">
            
            <span>Achievements</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#contact">
            
            <span>Contact</span>
            
          </a>
        </li>

        
        
      

      
      </ul>

    </div>
  </div>
</nav>


<article class="article" itemscope itemtype="http://schema.org/Article">

  


  <div class="article-container">
    <h1 itemprop="name">Spark Installation on Mac OS X</h1>

    

<div class="article-metadata">

  <span class="article-date">
    
    <time datetime="2017-06-28 00:00:00 &#43;0800 &#43;08" itemprop="datePublished dateModified">
      Wed, Jun 28, 2017
    </time>
  </span>
  <span itemscope itemprop="author publisher" itemtype="http://schema.org/Person">
    <meta itemprop="name" content="Zhang Hao">
  </span>

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    6 min read
  </span>
  

  
  

  

  
  

  

</div>

    
    <div class="article-style" itemprop="articleBody">
      <p>It is an introduction of Spark installation under localhost mode. Generally, Spark is available for multiple models: <strong>local</strong>, <strong>clustered&ndash;Spark Standalone</strong>, <strong>clustered&ndash;Spark on Apache Mesos</strong> and so forth, more details here: <a href="https://jaceklaskowski.gitbooks.io/mastering-apache-spark/spark-deployment-environments.html" target="_blank">link</a>.</p>

<h1 id="install-spark">Install Spark</h1>

<p>Since Spark requires Hadoop environment, so we need to install and configure Hadoop first. Here, I assume you already installed and configured Hadoop environment successfully. After that, we need to install Scala (<code>&gt;2.9.3</code> version).
First, go to <a href="http://www.scala-lang.org/download/" target="_blank">Scala official website</a> and download the newest version of Scala, then unzip and move it to <code>/usr/local/</code>:</p>

<pre><code class="language-bash">$ sudo tar -zxvf ~/downloads/scala-2.12.2.tgz -C /usr/local/
$ cd /usr/local/
$ sudo mv scala-2.12.2/ scala/
</code></pre>

<p>Open <code>/etc/profile</code>, input and save:</p>

<pre><code class="language-bash">export SCALA_HOME=/usr/local/scala
export PATH=$PATH:$SCALA_HOME/bin
</code></pre>

<p>Then <code>source profile</code> to activate the path declaration. (Simply, you can install Scala easily by Homebrew <code>brew install scala</code>, it will install Scala under <code>/usr/local/Cellar</code> directory).</p>

<p>After all things are done properly above, we can start to install Spark, go to <a href="http://spark.apache.org/downloads.html" target="_blank">Apache Spark official website</a> and download it (you need to select the spark release and package type to ensure the spark you download fits your environment). Then, unzip and move Spark to <code>/usr/local/</code>:</p>

<pre><code class="language-bash">$ sudo tar -zxvf ~/Dowmloads/spark-2.1.0-bin-hadoop2.7.tgz -C /usr/local/
$ cd /usr/local/
$ sudo mv spark-2.1.0-bin-hadoop2.7/ spark/
</code></pre>

<h1 id="configure-spark">Configure Spark</h1>

<p>Open <code>/etc/profile</code> and add:</p>

<pre><code class="language-bash">export SPARK_HOME=/usr/local/spark
export PATH=$PATH:$SPARK_HOME/bin
</code></pre>

<p>and we also need to configure <code>spark-env.sh</code>:</p>

<pre><code class="language-bash">$ cd /usr/local/spark/conf
$ sudo cp spark-env.sh.template spark-env.sh
$ sudo vim spark-env.sh
</code></pre>

<p>then add:</p>

<pre><code class="language-bash">export SCALA_HOME=/usr/local/scala
export SPARK_MASTER_IP=localhost
export SPARK_WORKER_MEMORY=4g
</code></pre>

<p>Here we finish the configuration of Spark environment variables. Then we need to test the Spark by executing <code>spark-shell</code> in the terminal. If it returns the error like:</p>

<pre><code class="language-bash">Mon Jul 03 11:19:17 SGT 2017 Thread[main,5,main] Cleanup action starting
ERROR XBM0H: Directory /usr/local/spark/conf/metastore_db cannot be created.
    at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
    at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
    at org.apache.derby.impl.services.monitor.StorageFactoryService$10.run(Unknown Source)
    at java.security.AccessController.doPrivileged(Native Method)
    ...
</code></pre>

<p>It means that you do not have permissions to write in that directory, try <code>sudo spark-shell</code>. Normally, it will return:</p>

<pre><code class="language-bash">Spark context Web UI available at http://192.168.68.237:4040
Spark context available as 'sc' (master = local[*], app id = local-1499055411427).
Spark session available as 'spark'.
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 2.1.0
      /_/
         
Using Scala version 2.11.8 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_131)
Type in expressions to have them evaluated.
Type :help for more information.

scala&gt;
</code></pre>

<p>Finally, Spark is installed successfully.</p>

<h1 id="use-spark-with-spark-shell">Use Spark with spark-shell</h1>

<p>After launching Spark (as above), we create a RDD from <code>/usr/local/spark/README.md</code>:</p>

<pre><code class="language-bash">scala&gt; val textFile = sc.textFile(&quot;file:///usr/local/spark/README.md&quot;)
&gt;textFile: org.apache.spark.rdd.RDD[String] = file:///usr/local/spark/README.md MapPartitionsRDD[1] at textFile at &lt;console&gt;:24
</code></pre>

<p>here, <code>file://</code> prefix (or ignore it) indicates to load a local file. If you want to access a HDFS file, you should indicate <code>hdfs://remote host/Hadoop port/filename</code> and you should make sure that the file has beed updated to HDFS. RDD supports two operation types:</p>

<ol>
<li>actions: manipulating on current dataset and return result.</li>
<li>transformations: transform and create a new dataset from current dataset.</li>
</ol>

<p>After the RDD is created, we can execute <code>count()</code> and <code>first()</code> method to get the following information:</p>

<pre><code class="language-bash">scala&gt; textFile.count()
res0: Long = 104

scala&gt; textFile.first()
res1: String = # Apache Spark
</code></pre>

<p>where <code>.count()</code> operation returns the number of item in RDD, for text file, it denotes the total lines of this text file. While <code>.first()</code> operation returns the content of first line of such text file.
For transformations, we can use filter transformatin to return a new RDD:</p>

<pre><code class="language-bash">scala&gt; var linesWithSpark = textFile.filter(line =&gt; line.contains(&quot;Spark&quot;))
linesWithSpark: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[2] at filter at &lt;console&gt;:26

scala&gt; linesWithSpark.count()
res2: Long = 20
</code></pre>

<p><code>.filter()</code> operation will filter the dataset with user-defined rules and return a new RDD (<code>linesWithSpark</code>). In practice, actions and transformations operations of RDD are able to handle various complex manipulations. For instance, we can find a line with highest number of words and return the number:</p>

<pre><code class="language-bash">scala&gt; import java.lang.Math
import java.lang.Math

scala&gt; textFile.map(line =&gt; line.split(&quot; &quot;).size).reduce((a, b) =&gt; Math.max(a, b))
res3: Int = 22
</code></pre>

<p>It is a lambda expression, firstly, <code>.map()</code> operation map each line to a Integer, which will create a new RDD, then execute <code>.reduce()</code> operation on this RDD to obtain maximum. Besides, Spark is able to implement Hadoop MapReduce too:</p>

<pre><code class="language-bash">scala&gt; val wordCounts = textFile.flatMap(line =&gt; line.split(&quot; &quot;)).map(word =&gt; (word, 1)).reduceByKey((a, b) =&gt; a + b)
wordCounts: org.apache.spark.rdd.RDD[(String, Int)] = ShuffledRDD[6] at reduceByKey at &lt;console&gt;:27

scala&gt; wordCounts.collect()
res4: Array[(String, Int)] = Array((package,1), (this,1), (Version&quot;](http://spark.apache.org/docs/latest/building-spark.html#specifying-the-hadoop-version),1), (Because,1), (Python,2), (page](http://spark.apache.org/documentation.html).,1), (cluster.,1), (its,1), ([run,1), (general,3), (have,1), (pre-built,1), (YARN,,1), ([http://spark.apache.org/developer-tools.html](the,1), (changed,1), (locally,2), (sc.parallelize(1,1), (only,1), (locally.,1), (several,1), (This,2), (basic,1), (Configuration,1), (learning,,1), (documentation,3), (first,1), (graph,1), (Hive,2), (info,1), ([&quot;Specifying,1), (&quot;yarn&quot;,1), ([params]`.,1), ([project,1), (prefer,1), (SparkPi,2), (&lt;http://spark.apache.org/&gt;,1), (engine,1), (version,1), (file,1), (documentation,,1), (MASTER,1), (example,3), ([&quot;Parallel,1), (are...
</code></pre>

<p>Above only give some simple examples of spark usage through Scala, you can get more examples and information through Google and related forum.</p>

<h1 id="create-spark-project-in-intellij">Create Spark Project in IntelliJ</h1>

<p>First create a maven project in IntelliJ and add the Spark dependency:</p>

<pre><code class="language-xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;
&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;
         xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;
    &lt;groupId&gt;com.isaac.spark&lt;/groupId&gt;
    &lt;artifactId&gt;SparkTest&lt;/artifactId&gt;
    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;
    &lt;build&gt;
        &lt;plugins&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;
                &lt;configuration&gt;
                    &lt;source&gt;1.8&lt;/source&gt;
                    &lt;target&gt;1.8&lt;/target&gt;
                &lt;/configuration&gt;
            &lt;/plugin&gt;
        &lt;/plugins&gt;
    &lt;/build&gt;
    &lt;properties&gt;
        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;
        &lt;spark.version&gt;2.1.0&lt;/spark.version&gt;
    &lt;/properties&gt;
    &lt;dependencies&gt;
        &lt;!-- https://mvnrepository.com/artifact/org.apache.spark/spark-core_2.10 --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;
            &lt;artifactId&gt;spark-core_2.10&lt;/artifactId&gt;
            &lt;version&gt;${spark.version}&lt;/version&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;
&lt;/project&gt;
</code></pre>

<p>Then create <code>WordCount.java</code> file:</p>

<pre><code class="language-java">package com.isaac.spark;
import org.apache.spark.SparkConf;
import org.apache.spark.api.java.JavaPairRDD;
import org.apache.spark.api.java.JavaRDD;
import org.apache.spark.api.java.JavaSparkContext;
import org.apache.spark.api.java.function.FlatMapFunction;
import org.apache.spark.api.java.function.Function2;
import org.apache.spark.api.java.function.PairFunction;
import scala.Tuple2;
import java.util.Arrays;
import java.util.Iterator;
import java.util.List;
import java.util.regex.Pattern;
/**
 * Created by zhanghao on 3/7/17.
 * @author ZHANG HAO
 */
public class WordCount {
    public static void main (String[] args) {
        // Create RDD object
        SparkConf conf = new SparkConf().setAppName(&quot;Simple Test&quot;).setMaster(&quot;local&quot;);
        JavaSparkContext sc = new JavaSparkContext(conf);
        // load data
        JavaRDD&lt;String&gt; textFile = sc.textFile(&quot;file:///Users/zhanghao/Desktop/test.txt&quot;);
        /*
         * User is able to handle different operations on the obtained DStream,
         * first we split the data, then use Map and ReduceByKey to calculation.
         */
        JavaRDD&lt;String&gt; words = textFile.flatMap(new FlatMapFunction&lt;String, String&gt;() {
            @Override
            public Iterator&lt;String&gt; call(String s) {
                return Arrays.asList(Pattern.compile(&quot; &quot;).split(s)).iterator();
            }
        });
        JavaPairRDD&lt;String, Integer&gt; ones = words.mapToPair(new PairFunction&lt;String, String, Integer&gt;() {
            @Override
            public Tuple2&lt;String, Integer&gt; call(String s) {
                return new Tuple2&lt;&gt;(s, 1);
            }
        });
        JavaPairRDD&lt;String, Integer&gt; counts = ones.reduceByKey(new Function2&lt;Integer, Integer, Integer&gt;() {
            @Override
            public Integer call(Integer i1, Integer i2) {
                return i1 + i2;
            }
        });
        List&lt;Tuple2&lt;String, Integer&gt;&gt; output = counts.collect();
        for (Tuple2&lt;?, ?&gt; tuple : output) {
            System.out.println(tuple._1() + &quot;: &quot; + tuple._2());
        }
        sc.stop();
    }
}
</code></pre>

<p>The output is shown below:</p>

<pre><code class="language-bash">Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
17/07/03 22:18:01 INFO SparkContext: Running Spark version 2.1.0
17/07/03 22:18:01 WARN SparkContext: Support for Scala 2.10 is deprecated as of Spark 2.1.0
17/07/03 22:18:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
...
17/07/03 22:18:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
17/07/03 22:18:06 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1979 bytes result sent to driver
17/07/03 22:18:06 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 55 ms on localhost (executor driver) (1/1)
17/07/03 22:18:06 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/07/03 22:18:06 INFO DAGScheduler: ResultStage 1 (collect at WordCount.java:54) finished in 0.056 s
Hello: 1
love: 1
Java: 1
I: 1
Spark.: 1
and: 1
World,: 1
17/07/03 22:18:06 INFO DAGScheduler: Job 0 finished: collect at WordCount.java:54, took 0.561756 s
17/07/03 22:18:06 INFO SparkUI: Stopped Spark web UI at http://192.168.1.4:4040
17/07/03 22:18:07 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
...
</code></pre>

<h1 id="reference">Reference</h1>

<ul>
<li><a href="http://codingxiaxw.cn/2016/12/07/60-mac-spark/" target="_blank">Install and Use Spark under Mac</a></li>
</ul>
    </div>

    


<div class="article-tags">
  
  <a class="btn btn-primary btn-outline" href="/tags/setting">setting</a>
  
  <a class="btn btn-primary btn-outline" href="/tags/mac-os">mac-os</a>
  
</div>




    
    
    <div class="article-widget">
      <div class="hr-light"></div>
      <h3>Related</h3>
      <ul>
        
        <li><a href="/post/install_hadoop_mac/">Hadoop Installation on Mac OS X</a></li>
        
        <li><a href="/post/install_xgboost_mac/">Install XGBoost on Mac OS X</a></li>
        
        <li><a href="/post/mac_dict_extension/">MacOS Dictionary Application Extension</a></li>
        
        <li><a href="/post/install_opencv_java/">Installation of OpenCV for Java</a></li>
        
        <li><a href="/post/config_git_eclipse/">Configure BitBucket Git Repository in Eclipse</a></li>
        
      </ul>
    </div>
    

    

    


  </div>
</article>

<footer class="site-footer">
  <div class="container">
    <p class="powered-by">

      &copy; 2017-2018 &middot; 

      <strong>Isaac Changhau (Zhang Hao)</strong>
      

      <span class="pull-right" aria-hidden="true">
        <a href="#" id="back_to_top">
          <span class="button_icon">
            <i class="fa fa-chevron-up fa-2x"></i>
          </span>
        </a>
      </span>

    </p>
  </div>
</footer>


<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <button type="button" class="close btn-large" data-dismiss="modal">&times;</button>
        <h4 class="modal-title">Cite</h4>
      </div>
      <div>
        <pre><code class="modal-body tex"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-primary btn-outline js-copy-cite" href="#" target="_blank">
          <i class="fa fa-copy"></i> Copy
        </a>
        <a class="btn btn-primary btn-outline js-download-cite" href="#" target="_blank">
          <i class="fa fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

    

    
    

    

    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.2.1/jquery.min.js" integrity="sha512-3P8rXCuGJdNZOnUx/03c1jOTnMn3rP63nBip5gOP2qmUh5YAdVAvFZ1E+QLZZbC1rtMrQb+mah3AfYW11RUrWA==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.3/imagesloaded.pkgd.min.js" integrity="sha512-umsR78NN0D23AzgoZ11K7raBD+R6hqKojyBZs1w8WvYlsI+QuKRGBx3LFCwhatzBunCjDuJpDHwxD13sLMbpRA==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha512-iztkobsvnjKfAtTNdHkGVjAYTrrtlC7mGp/54c40wowO7LhURYl3gVzzcEqGl/qKXQltJ2HwMrdLcNUdo+N/RQ==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.4/isotope.pkgd.min.js" integrity="sha512-VDBOIlDbuC4VWxGJNmuFRQ0Li0SKkDpmGyuhAG5LTDLd/dJ/S0WMVxriR2Y+CyPL5gzjpN4f/6iqWVBJlht0tQ==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>
    
    
    <script src="/js/hugo-academic.js"></script>
    

    
    
      
      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>
      

      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/java.min.js"></script>
      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/python.min.js"></script>
      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/scala.min.js"></script>
      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/javascript.min.js"></script>
      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/c.min.js"></script>
      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/html.min.js"></script>
      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/bash.min.js"></script>
      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/xml.min.js"></script>
      

      

      <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({ 
          tex2jax: { 
            inlineMath: [['$','$'], ['\\(','\\)']] 
          } 
        });
    </script>
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_CHTML" integrity="sha512-xAWI9i8WMRLdgksuhaMCYMTw9D+MEc2cYVBApWwGRJ0cdcywTjMovOfJnlGt9LlEQj6QzyMzpIZLMYujetPcQg==" crossorigin="anonymous"></script>
    
    
    

  </body>
</html>

