<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="theme" content="hugo-academic">
  <meta name="generator" content="Hugo 0.41" />
  <meta name="author" content="Zhang Hao">

  
  
  
  
    
      
    
  
  <meta name="description" content="摘自周志华《机器学习》第二章&ndash;模型评估与选择。
根据训练数据是否拥有标记信息，学习任务可大致分为两大类: “监督学习” (supervised learning) 和“无监督学习” (unsupervised learning)，分类 (classification) 和回归 (regression) 是前者的代表，而聚类 (clustering) 是后者的代表。 机器学习的目标是使学得的模型能很好的适用于“新样本”，而不是仅仅在训练样本上工作得很好；即便对聚类这样的无监督学习任务，我们也希望学得的簇划分能适用于没在训练集中出现的样本。学得模型适用于新样本的能力，称为泛化 (generalization) 能力。具有强泛化能力的模型能很好的适用于整个样本空间。
经验误差与过拟合 错误率 (error rate): 为分类错误的样本数占样本总数的比例，即在$m$个样本中有$a$个样本分类错误，则错误率$E=\frac{a}{m}$，相应的$1-\frac{a}{m}$称为精度 (accuracy)，即“精度=1-错误率”。
误差 (error): 学习器实际预测输出与样本的真实输出之间的差异。
训练误差 (training error)或“经验误差”(empirical error): 学习器在训练集上的误差。
泛化误差 (generalization error): 学习器在新样本上的误差。 过拟合 (overfitting): 指在拟合一个统计模型时，使用过多参数。对比于可获取的数据总量来说，一个荒谬的模型只要足够复杂，是可以完美地适应数据。过拟合一般可以视为违反奥卡姆剃刀原则。当可选择的参数的自由度超过数据所包含信息内容时，这会导致最后（拟合后）模型使用任意的参数，这会减少或破坏模型一般化的能力更甚于适应数据。过拟合的可能性不只取决于参数个数和数据，也跟模型架构与数据的一致性有关。此外对比于数据中预期的噪声或错误数量，跟模型错误的数量也有关。
欠拟合 (underfitting): 指模型没有很好地捕捉到数据特征，不能够很好地拟合数据，与过拟合相反。
评估方法 留出法 (hold-out): 直接将数据集D划分为两个互斥的集合，其中一个集合作为训练集$S$，另一个作为测试集$T$，即$D=S\cup T$，$S\cap T=\varnothing$。在$S$上训练出模型后，用$T$来评估器测试误差，作为泛化误差的估计。拆分数据集$D$一般采用“分层采样” (stratified sampling)。
交叉验证法 (cross validation): 先将数据集$D$划分为$k$个大小相似的互斥子集，即$D=D_{1}\cup D_{2} \cup &hellip;\cup D_{k}$，$D_{i}\cap D_{j}=\varnothing (i\neq j)$。每个子集$D_{i}$都尽可能保持数据分布的一致性，即从$D$中通过分层采样得到。然后，每次用k-1个子集的并集作为训练集，余下的那个子集作为测试集，这样就可以获得k组训练/测试集，从而可进行k次训练和测试，最终返回k次测试结果的均值。这种方法的稳定性 (stability) 和保真性 (fidelity) 很大程度上取决于k的取值，通常这种方法又称为“k折交叉验证” (k-fold cross validation)。通常k的取值为10。
自助法 (bootstrapping): 以自助采样 (bootstrap sampling) 为基础，给定包含$m$个样本的数据集$D$，对它进行采样产生数据集$D&rsquo;$，每次随机从$D$中挑选一个样本，将其拷贝到$D&rsquo;$，然后再将该样本放回初始数据集$D$中，使得该样本在下次采样时仍有可能被采到；这个过程重复执行$m$次后，就得到包含$m$个样本的数据集$D&rsquo;$，这就是自助采样的结果。显然$D$中有一部分样本会在$D&rsquo;$中多次出现，而另一部分样本不出现。粗略估计，样本在$m$次采样中始终不被采到的概率是$(1-\frac{1}{m})^{m}$，取极限得到 $$ \lim_{m \to \infty}(1-\frac{1}{m})^{m}\longmapsto\frac{1}{e}\approx0.">

  
  <link rel="alternate" hreflang="en-us" href="https://isaacchanghau.github.io/post/ml_zzh_note_1/">

  


  

  
  
  <meta name="theme-color" content="#3f51b5">
  
  
  
  
    
  
  
    
    
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">
    
  
  
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha512-6MXa8B6uaO18Hid6blRMetEIoPqHf7Ux1tnyIQdpt9qI5OACx7C+O3IVTr98vwGnlcg0LOLa02i9Y1HpVhlfiw==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.1/css/academicons.min.css" integrity="sha512-NThgw3XKQ1absAahW6to7Ey42uycrVvfNfyjqcFNgCmOCQ5AR4AO0SiXrN+8ZtYeappp56lk1WtvjVmEa+VR6A==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha512-SfTiTlX6kk+qitfevl/7LibUOeJWlt9rbyDn92a1DqWOw9vWG2MFoays0sgObmWazO5BQPiFucnnEAjpAB+/Sw==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">
  
  
  
  
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Playfair&#43;Display:400,700%7cFauna&#43;One">
  
  <link rel="stylesheet" href="/styles.css">
  

  

  
  <link rel="alternate" href="https://isaacchanghau.github.io/index.xml" type="application/rss+xml" title="Isaac Changhau">
  <link rel="feed" href="https://isaacchanghau.github.io/index.xml" type="application/rss+xml" title="Isaac Changhau">
  

  <link rel="manifest" href="/site.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="https://isaacchanghau.github.io/post/ml_zzh_note_1/">

  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="twitter:site" content="@https://twitter.com/IsaacChanghau">
  <meta property="twitter:creator" content="@https://twitter.com/IsaacChanghau">
  
  <meta property="og:site_name" content="Isaac Changhau">
  <meta property="og:url" content="https://isaacchanghau.github.io/post/ml_zzh_note_1/">
  <meta property="og:title" content="Machine Learning Note (1): Model Evaluation and Selection | Isaac Changhau">
  <meta property="og:description" content="摘自周志华《机器学习》第二章&ndash;模型评估与选择。
根据训练数据是否拥有标记信息，学习任务可大致分为两大类: “监督学习” (supervised learning) 和“无监督学习” (unsupervised learning)，分类 (classification) 和回归 (regression) 是前者的代表，而聚类 (clustering) 是后者的代表。 机器学习的目标是使学得的模型能很好的适用于“新样本”，而不是仅仅在训练样本上工作得很好；即便对聚类这样的无监督学习任务，我们也希望学得的簇划分能适用于没在训练集中出现的样本。学得模型适用于新样本的能力，称为泛化 (generalization) 能力。具有强泛化能力的模型能很好的适用于整个样本空间。
经验误差与过拟合 错误率 (error rate): 为分类错误的样本数占样本总数的比例，即在$m$个样本中有$a$个样本分类错误，则错误率$E=\frac{a}{m}$，相应的$1-\frac{a}{m}$称为精度 (accuracy)，即“精度=1-错误率”。
误差 (error): 学习器实际预测输出与样本的真实输出之间的差异。
训练误差 (training error)或“经验误差”(empirical error): 学习器在训练集上的误差。
泛化误差 (generalization error): 学习器在新样本上的误差。 过拟合 (overfitting): 指在拟合一个统计模型时，使用过多参数。对比于可获取的数据总量来说，一个荒谬的模型只要足够复杂，是可以完美地适应数据。过拟合一般可以视为违反奥卡姆剃刀原则。当可选择的参数的自由度超过数据所包含信息内容时，这会导致最后（拟合后）模型使用任意的参数，这会减少或破坏模型一般化的能力更甚于适应数据。过拟合的可能性不只取决于参数个数和数据，也跟模型架构与数据的一致性有关。此外对比于数据中预期的噪声或错误数量，跟模型错误的数量也有关。
欠拟合 (underfitting): 指模型没有很好地捕捉到数据特征，不能够很好地拟合数据，与过拟合相反。
评估方法 留出法 (hold-out): 直接将数据集D划分为两个互斥的集合，其中一个集合作为训练集$S$，另一个作为测试集$T$，即$D=S\cup T$，$S\cap T=\varnothing$。在$S$上训练出模型后，用$T$来评估器测试误差，作为泛化误差的估计。拆分数据集$D$一般采用“分层采样” (stratified sampling)。
交叉验证法 (cross validation): 先将数据集$D$划分为$k$个大小相似的互斥子集，即$D=D_{1}\cup D_{2} \cup &hellip;\cup D_{k}$，$D_{i}\cap D_{j}=\varnothing (i\neq j)$。每个子集$D_{i}$都尽可能保持数据分布的一致性，即从$D$中通过分层采样得到。然后，每次用k-1个子集的并集作为训练集，余下的那个子集作为测试集，这样就可以获得k组训练/测试集，从而可进行k次训练和测试，最终返回k次测试结果的均值。这种方法的稳定性 (stability) 和保真性 (fidelity) 很大程度上取决于k的取值，通常这种方法又称为“k折交叉验证” (k-fold cross validation)。通常k的取值为10。
自助法 (bootstrapping): 以自助采样 (bootstrap sampling) 为基础，给定包含$m$个样本的数据集$D$，对它进行采样产生数据集$D&rsquo;$，每次随机从$D$中挑选一个样本，将其拷贝到$D&rsquo;$，然后再将该样本放回初始数据集$D$中，使得该样本在下次采样时仍有可能被采到；这个过程重复执行$m$次后，就得到包含$m$个样本的数据集$D&rsquo;$，这就是自助采样的结果。显然$D$中有一部分样本会在$D&rsquo;$中多次出现，而另一部分样本不出现。粗略估计，样本在$m$次采样中始终不被采到的概率是$(1-\frac{1}{m})^{m}$，取极限得到 $$ \lim_{m \to \infty}(1-\frac{1}{m})^{m}\longmapsto\frac{1}{e}\approx0.">
  <meta property="og:locale" content="en-us">
  
  <meta property="article:published_time" content="2017-04-28T00:00:00&#43;08:00">
  
  <meta property="article:modified_time" content="2017-04-28T00:00:00&#43;08:00">
  

  

  <title>Machine Learning Note (1): Model Evaluation and Selection | Isaac Changhau</title>

</head>
<body id="top" data-spy="scroll" data-target="#toc" data-offset="71" >

<nav class="navbar navbar-default navbar-fixed-top" id="navbar-main">
  <div class="container">

    
    <div class="navbar-header">
      
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse"
              data-target=".navbar-collapse" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      
      <a class="navbar-brand" href="/">Isaac Changhau</a>
    </div>

    
    <div class="collapse navbar-collapse">

      
      
      <ul class="nav navbar-nav navbar-right">
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#about">
            
            <span>Home</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#projects">
            
            <span>Projects</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#posts">
            
            <span>Posts</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#tags">
            
            <span>Tags</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#publications">
            
            <span>Publications</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#achievements">
            
            <span>Achievements</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#contact">
            
            <span>Contact</span>
            
          </a>
        </li>

        
        
      

      
      </ul>

    </div>
  </div>
</nav>


<article class="article" itemscope itemtype="http://schema.org/Article">

  


  <div class="article-container">
    <h1 itemprop="name">Machine Learning Note (1): Model Evaluation and Selection</h1>

    

<div class="article-metadata">

  <span class="article-date">
    
    <time datetime="2017-04-28 00:00:00 &#43;0800 &#43;08" itemprop="datePublished dateModified">
      Fri, Apr 28, 2017
    </time>
  </span>
  <span itemscope itemprop="author publisher" itemtype="http://schema.org/Person">
    <meta itemprop="name" content="Zhang Hao">
  </span>

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    1 min read
  </span>
  

  
  

  

  
  

  

</div>

    
    <div class="article-style" itemprop="articleBody">
      

<p>摘自周志华《机器学习》第二章&ndash;模型评估与选择。</p>

<p>根据训练数据是否拥有标记信息，学习任务可大致分为两大类: “<strong>监督学习</strong>” (supervised learning) 和“<strong>无监督学习</strong>” (unsupervised learning)，分类 (classification) 和回归 (regression) 是前者的代表，而聚类 (clustering) 是后者的代表。
机器学习的目标是使学得的模型能很好的适用于“新样本”，而不是仅仅在训练样本上工作得很好；即便对聚类这样的无监督学习任务，我们也希望学得的簇划分能适用于没在训练集中出现的样本。学得模型适用于新样本的能力，称为泛化 (generalization) 能力。具有强泛化能力的模型能很好的适用于整个样本空间。</p>

<h1 id="经验误差与过拟合">经验误差与过拟合</h1>

<p><strong>错误率</strong> (error rate): 为分类错误的样本数占样本总数的比例，即在$m$个样本中有$a$个样本分类错误，则错误率$E=\frac{a}{m}$，相应的$1-\frac{a}{m}$称为<strong>精度</strong> (accuracy)，即“精度=1-错误率”。</p>

<p><strong>误差</strong> (error): 学习器实际预测输出与样本的真实输出之间的差异。</p>

<p><strong>训练误差</strong> (training error)或“<strong>经验误差</strong>”(empirical error): 学习器在训练集上的误差。</p>

<p><strong>泛化误差</strong> (generalization error): 学习器在新样本上的误差。
<strong>过拟合</strong> (<a href="https://en.wikipedia.org/wiki/Overfitting" target="_blank">overfitting</a>): 指在拟合一个统计模型时，使用过多参数。对比于可获取的数据总量来说，一个荒谬的模型只要足够复杂，是可以完美地适应数据。过拟合一般可以视为违反奥卡姆剃刀原则。当可选择的参数的自由度超过数据所包含信息内容时，这会导致最后（拟合后）模型使用任意的参数，这会减少或破坏模型一般化的能力更甚于适应数据。过拟合的可能性不只取决于参数个数和数据，也跟模型架构与数据的一致性有关。此外对比于数据中预期的噪声或错误数量，跟模型错误的数量也有关。</p>

<p><strong>欠拟合</strong> (underfitting): 指模型没有很好地捕捉到数据特征，不能够很好地拟合数据，与过拟合相反。</p>

<h1 id="评估方法">评估方法</h1>

<p><strong>留出法</strong> (hold-out): 直接将数据集D划分为两个互斥的集合，其中一个集合作为训练集$S$，另一个作为测试集$T$，即$D=S\cup T$，$S\cap T=\varnothing$。在$S$上训练出模型后，用$T$来评估器测试误差，作为泛化误差的估计。拆分数据集$D$一般采用“分层采样” (<a href="https://en.wikipedia.org/wiki/Stratified_sampling" target="_blank">stratified sampling</a>)。</p>

<p><strong>交叉验证法</strong> (cross validation): 先将数据集$D$划分为$k$个大小相似的互斥子集，即$D=D_{1}\cup D_{2} \cup &hellip;\cup D_{k}$，$D_{i}\cap D_{j}=\varnothing (i\neq j)$。每个子集$D_{i}$都尽可能保持数据分布的一致性，即从$D$中通过分层采样得到。然后，每次用k-1个子集的并集作为训练集，余下的那个子集作为测试集，这样就可以获得k组训练/测试集，从而可进行k次训练和测试，最终返回k次测试结果的均值。这种方法的稳定性 (stability) 和保真性 (fidelity) 很大程度上取决于k的取值，通常这种方法又称为“k折交叉验证” (k-fold cross validation)。通常k的取值为10。</p>

<p><strong>自助法</strong> (bootstrapping): 以自助采样 (bootstrap sampling) 为基础，给定包含$m$个样本的数据集$D$，对它进行采样产生数据集$D&rsquo;$，每次随机从$D$中挑选一个样本，将其拷贝到$D&rsquo;$，然后再将该样本放回初始数据集$D$中，使得该样本在下次采样时仍有可能被采到；这个过程重复执行$m$次后，就得到包含$m$个样本的数据集$D&rsquo;$，这就是自助采样的结果。显然$D$中有一部分样本会在$D&rsquo;$中多次出现，而另一部分样本不出现。粗略估计，样本在$m$次采样中始终不被采到的概率是$(1-\frac{1}{m})^{m}$，取极限得到
$$
\lim_{m \to \infty}(1-\frac{1}{m})^{m}\longmapsto\frac{1}{e}\approx0.368
$$
即通过自助采样，初始数据集$D$中约有36.8%的样本未出现在采样数据集$D&rsquo;$中，于是可以将$D&rsquo;$用作训练集，$D-D&rsquo;$用作测试集。这种方式的测试结果也称为“包外估计” (out-of-bag estimate)。</p>

<h1 id="性能度量">性能度量</h1>

<p>在预测任务中，给定样例集$D=\lbrace (x_{1},y_{1}),(x_{2},y_{2}), \dots ,(x_{m},y_{m})\rbrace$，其中$y_{i}$是示例$x_{i}$的真实标记 (label)。要评估学习器$f$的性能，就要把学习器预测结果$f(x)$与真实标记$y$进行比较。</p>

<p>例如，回归(regression)任务最常用的性能度量是“<strong>均方误差</strong>” (mean squared error)
$$
E(f;D)=\frac{1}{m}\sum_{i=1}^m (f(x_{i})-y_{i})^{2}
$$
更一般的，对于数据分布$\mathcal{D}$和概率密度分布函数$p(\cdot)$，均方误差可描述为
$$
E(f;\mathcal{D})=\int_{x \sim \mathcal{D}}(f(x)-y)^{2}p(x)dx
$$</p>

<h1 id="错误率与精度">错误率与精度</h1>

<p>对样例集$D$，分类错误率定义为
$$
E(f;D)=\frac{1}{m}\sum_{i=1}^m(f(x_{i})\neq y_{i})
$$
精度则定义为
$$
acc(f;D)=\frac{1}{m}\sum_{i=1}^m(f(x_{i})=y_{i})=1-E(f;D)
$$</p>

<h1 id="查准率-percision-查全率-recall-与f1">查准率(percision)、查全率(recall)与F1</h1>

<p>真正例(true positive): $TP$，假正例(false positive): $FP$，真反例(true negative): $TN$，假反例(false negative): $FN$。显然，$TP+FP+TN+FN=样例总数$。如下是分类结果的“混淆矩阵”(confusion matrix):
<img src="/img/machinelearning/modelselection/confusionmatrix.png" alt="confusion matrix" />
查准率$P$和查全率$R$分别定义为
$$
P=\frac{TP}{TP+FP}, R=\frac{TP}{TP+FN}
$$
查准率和查全率是一对矛盾的度量，一般来说，查准率高时，查全率往往偏低，二查全率高时，查准率往往偏低。以查准率为纵轴，查全率为横轴作图，可以得到“P-R曲线”
<img src="/img/machinelearning/modelselection/p-rcurve.png" alt="p-r curve" />
图中“平衡点” (Break-Event Point, BER)是“查准率=查全率”时的取值。BER度量相对简单，更常用的是$F1$度量:
$$
F1=\frac{2\times P\times R}{P+R}=\frac{2\times TP}{样例总数+TP-TN}
$$
F1度量的一般形式为$F_{\beta}$，能表达出对查准率／查全率的不同偏好
$$
F_{\beta}=\frac{(1+\beta^{2})\times P\times R}{(\beta^{2}\times P)+R}
$$
其中$\beta&gt;0$度量了查全率对查准率的相对重要性。关于“宏查准率”(macro-P)、“微查准率” (micro-P)等知识点参照书P-32页。</p>

<h1 id="roc和auc">ROC和AUC</h1>

<p>“真正例率” (True Positive Rate, TPR): $TPR=\frac{TP}{TP+FN}$，“假正例率” (False Positive Rate, FPR): $FPR=\frac{FP}{TN+FP}$
<img src="/img/machinelearning/modelselection/roc.png" alt="roc curve" />
图中对角线对应于“随即猜测”模型。进行学习器比较时，若一个学习器的ROC曲线被另一个学习器的曲线完全“包住”，则后者的性能优于前者；若两个学习器的ROC曲线发生交叉，则很难断定孰优孰劣。若一定要进行比较，则比较ROC曲线下的面积，即AUC (Area Under ROC Curve)。如上图(b)，AUC可通过对ROC曲线下各部分面积求和而得。假定ROC曲线是由坐标为$\lbrace (x_{1},y_{1}),(x_{2},y_{2}),\dots ,(x_{m},y_{m})\rbrace$的按序连接而形成$(x_{1}=0,x_{m}=1)$，则AUC可估算为
$$
AUC=\frac{1}{2}\sum_{i=1}^{m-1}(x_{i+1}-x_{i})\cdot (y_{i}+y_{i+1})
$$
形式化的看，AUC考虑的是样本预测的排序质量，因此它与排序误差有紧密联系。给定$m^{+}$个正例和$m^{-}$个反例，令$D^{+}$和$D^{-}$分别表示正、反例集合，则排序“损失” (loss)定义为
$$
l_{rank}=\frac{1}{m^{+}m^{-}}\sum_{x^{+}\in D^{+}}\sum_{x^{-}\in D^{-}}\lbrace (f(x^{+}\leq f(x^{-}))+\frac{1}{2}(f(x^{+})=f(x^{-}))\rbrace
$$
即考虑每一对正、反例，若正例的预测值小于反例，则记一个“罚分”，若相等，则记0.5个“罚分”。$l-{rank}$对应的是ROC曲线上的面积，若一个正例在ROC曲线上对应标记点坐标为$(x,y)$，则$x$恰是排序在其之前的反例所占的比例，即假正例率。因此$$AUC=1-l_{rank}$$</p>

<h1 id="偏差与方差">偏差与方差</h1>

<p>偏差-方差分解试图对学习算法的期望泛化错误率进行拆解。对测试样本$x$，令$y_{D}$为$x$在数据集中的标记，$y$为$x$的真实标记，$f(x;D)$为训练集$D$上学得模型$f$在$x$上的预测输出。以<strong>回归</strong>任务为例，学习算法的期望预测为
$$
\bar{f}(x)=\mathbb{E}_{D}[f(x;D)]
$$
使用样本数相同的不同训练集产生的方差为
$$
var(x)=\mathbb{E}_{D}\lbrack (f(x:D)-\bar{f}(x))^{2}\rbrack
$$
噪声为
$$
\varepsilon^{2}=\mathbb{E}_{D}[(y_{D}-y)^{2}]
$$
期望输出与真实标记的差别称为偏差(bias)，即
$$
bias^{2}(x)=(\bar{f}(x)-y)^{2}
$$
为便于讨论，假定噪声期望为0，即$\mathbb{E}_{D}[y_{D}-y]=0$。通过简单的多项式展开合并，可对算法的期望泛化误差进行分解:
<img src="/img/machinelearning/modelselection/biasdecompose.png" alt="generalization bias decompose" />
于是，$E(f;D)=bias^{2}(x)+var(x)+\varepsilon^{2}$。也就是说，泛化误差可分解为偏差、方差和噪声之和。偏差度量了学习算法的期望预测与真实结果的偏离程度，即刻画了学习算法本身的拟合能力；方差度量了同样大小的训练集变动所导致的学习性能变化，即刻画了数据扰动所造成的影响；噪声则表达了当前任务上任何学习算法所能达到的期望泛化误差的下届，即刻画了学习问题本身的难度。偏差-方差分解说明，泛化性能是由学习算法的能力、数据的充分性以及学习任务本身难度所共同决定的。给定学习任务，为了取得好的泛化性能，则需要使偏差较小，即能够充分拟合数据，并且使方差较小，即使得数据扰动产生的影响小。
一般来说，方差与偏差时有冲突的，这称为偏差-方差窘境(bias-variance dilemma)。如图
<img src="/img/machinelearning/modelselection/bias-variance-dilemma.png" alt="bias-variance dilemma" />
给定学习任务，假设我们能控制学习算法的训练程度，在训练不足时，学习器的拟合能力不够强，训练数据的扰动不足以时学习器发生显著变化，此时偏差主导了泛化错误率；随着训练程度的加深，学习器的拟合能力逐渐增强，训练数据发生的扰动渐渐能被学习器学到，方差逐渐主导了泛化错误率；在训练程度充足后，学习器的拟合能力已非常强，训练数据发生的轻微扰动都会导致学习器发生显著变化，若训练数据自身的、非全局的特性被学习器学到了，则将发生过拟合。</p>

    </div>

    


<div class="article-tags">
  
  <a class="btn btn-primary btn-outline" href="/tags/machine-learning">machine-learning</a>
  
</div>




    
    

    

    


  </div>
</article>

<footer class="site-footer">
  <div class="container">
    <p class="powered-by">

      &copy; 2017-2018 &middot; 

      <strong>Isaac Changhau (Zhang Hao)</strong>
      

      <span class="pull-right" aria-hidden="true">
        <a href="#" id="back_to_top">
          <span class="button_icon">
            <i class="fa fa-chevron-up fa-2x"></i>
          </span>
        </a>
      </span>

    </p>
  </div>
</footer>


<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <button type="button" class="close btn-large" data-dismiss="modal">&times;</button>
        <h4 class="modal-title">Cite</h4>
      </div>
      <div>
        <pre><code class="modal-body tex"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-primary btn-outline js-copy-cite" href="#" target="_blank">
          <i class="fa fa-copy"></i> Copy
        </a>
        <a class="btn btn-primary btn-outline js-download-cite" href="#" target="_blank">
          <i class="fa fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

    

    
    

    

    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.2.1/jquery.min.js" integrity="sha512-3P8rXCuGJdNZOnUx/03c1jOTnMn3rP63nBip5gOP2qmUh5YAdVAvFZ1E+QLZZbC1rtMrQb+mah3AfYW11RUrWA==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.3/imagesloaded.pkgd.min.js" integrity="sha512-umsR78NN0D23AzgoZ11K7raBD+R6hqKojyBZs1w8WvYlsI+QuKRGBx3LFCwhatzBunCjDuJpDHwxD13sLMbpRA==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha512-iztkobsvnjKfAtTNdHkGVjAYTrrtlC7mGp/54c40wowO7LhURYl3gVzzcEqGl/qKXQltJ2HwMrdLcNUdo+N/RQ==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.4/isotope.pkgd.min.js" integrity="sha512-VDBOIlDbuC4VWxGJNmuFRQ0Li0SKkDpmGyuhAG5LTDLd/dJ/S0WMVxriR2Y+CyPL5gzjpN4f/6iqWVBJlht0tQ==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>
    
    
    <script src="/js/hugo-academic.js"></script>
    

    
    
      
      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>
      

      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/java.min.js"></script>
      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/python.min.js"></script>
      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/scala.min.js"></script>
      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/javascript.min.js"></script>
      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/c.min.js"></script>
      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/html.min.js"></script>
      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/bash.min.js"></script>
      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/xml.min.js"></script>
      

      

      <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({ 
          tex2jax: { 
            inlineMath: [['$','$'], ['\\(','\\)']] 
          } 
        });
    </script>
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_CHTML" integrity="sha512-xAWI9i8WMRLdgksuhaMCYMTw9D+MEc2cYVBApWwGRJ0cdcywTjMovOfJnlGt9LlEQj6QzyMzpIZLMYujetPcQg==" crossorigin="anonymous"></script>
    
    
    

  </body>
</html>

