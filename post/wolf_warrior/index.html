<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="theme" content="hugo-academic">
  <meta name="generator" content="Hugo 0.40.1" />
  <meta name="author" content="Zhang Hao">

  
  
  
  
    
      
    
  
  <meta name="description" content="想要分析“战狼II”的影评数据，首先需要获取这些数据，这里使用 Python 的 requests 包进行网页请求，并使用正则表达式匹配出我们需要的数据。首先使用Chrome打开豆瓣影评·战狼II的网页 (https://movie.douban.com/subject/26363254/comments?start=0)，使用 Developer Tools 对当前页面做一个简单的了解和分析，如下图： 我们发现页面的所有评论、评论者、投票、评价等级等信息均存储在 &lt;div class=&quot;comment-item&quot; ...&gt; 标签下。而转向下一页面的链接信息存储在 &lt;div id=&quot;paginator&quot;&gt; 标签的 &lt;a href=&quot;?start=26&amp;amp;limit=20&amp;amp;sort=new_score&amp;amp;status=P&quot; ... class=&quot;next&quot;&gt;... 中。因此，可以针对这部分 HTML 标签创建相应的正则表达式来获取数据。简易的爬虫代码如下：
import requests import re import pandas as pd url_first = &#39;https://movie.douban.com/subject/26363254/comments?start=0&#39; # start page head = {&#39;User-Agent&#39;:&#39;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.79 Safari/537.36&#39;} cookies = {&#39;cookie&#39;:&#39;you own cookies} #cookie of your account html = requests.get(url_first, headers=head, cookies=cookies) # get first page re_page = re.">

  
  <link rel="alternate" hreflang="en-us" href="https://isaacchanghau.github.io/post/wolf_warrior/">

  


  

  
  
  <meta name="theme-color" content="#3f51b5">
  
  
  
  
    
  
  
    
    
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">
    
  
  
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha512-6MXa8B6uaO18Hid6blRMetEIoPqHf7Ux1tnyIQdpt9qI5OACx7C+O3IVTr98vwGnlcg0LOLa02i9Y1HpVhlfiw==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.1/css/academicons.min.css" integrity="sha512-NThgw3XKQ1absAahW6to7Ey42uycrVvfNfyjqcFNgCmOCQ5AR4AO0SiXrN+8ZtYeappp56lk1WtvjVmEa+VR6A==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha512-SfTiTlX6kk+qitfevl/7LibUOeJWlt9rbyDn92a1DqWOw9vWG2MFoays0sgObmWazO5BQPiFucnnEAjpAB+/Sw==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">
  
  
  
  
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Playfair&#43;Display:400,700%7cFauna&#43;One">
  
  <link rel="stylesheet" href="/styles.css">
  

  

  
  <link rel="alternate" href="https://isaacchanghau.github.io/index.xml" type="application/rss+xml" title="Isaac Changhau">
  <link rel="feed" href="https://isaacchanghau.github.io/index.xml" type="application/rss+xml" title="Isaac Changhau">
  

  <link rel="manifest" href="/site.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="https://isaacchanghau.github.io/post/wolf_warrior/">

  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="twitter:site" content="@https://twitter.com/IsaacChanghau">
  <meta property="twitter:creator" content="@https://twitter.com/IsaacChanghau">
  
  <meta property="og:site_name" content="Isaac Changhau">
  <meta property="og:url" content="https://isaacchanghau.github.io/post/wolf_warrior/">
  <meta property="og:title" content="Analyzing Wolf Warrior II Movie Comments using Python | Isaac Changhau">
  <meta property="og:description" content="想要分析“战狼II”的影评数据，首先需要获取这些数据，这里使用 Python 的 requests 包进行网页请求，并使用正则表达式匹配出我们需要的数据。首先使用Chrome打开豆瓣影评·战狼II的网页 (https://movie.douban.com/subject/26363254/comments?start=0)，使用 Developer Tools 对当前页面做一个简单的了解和分析，如下图： 我们发现页面的所有评论、评论者、投票、评价等级等信息均存储在 &lt;div class=&quot;comment-item&quot; ...&gt; 标签下。而转向下一页面的链接信息存储在 &lt;div id=&quot;paginator&quot;&gt; 标签的 &lt;a href=&quot;?start=26&amp;amp;limit=20&amp;amp;sort=new_score&amp;amp;status=P&quot; ... class=&quot;next&quot;&gt;... 中。因此，可以针对这部分 HTML 标签创建相应的正则表达式来获取数据。简易的爬虫代码如下：
import requests import re import pandas as pd url_first = &#39;https://movie.douban.com/subject/26363254/comments?start=0&#39; # start page head = {&#39;User-Agent&#39;:&#39;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.79 Safari/537.36&#39;} cookies = {&#39;cookie&#39;:&#39;you own cookies} #cookie of your account html = requests.get(url_first, headers=head, cookies=cookies) # get first page re_page = re.">
  <meta property="og:locale" content="en-us">
  
  <meta property="article:published_time" content="2017-09-11T00:00:00&#43;08:00">
  
  <meta property="article:modified_time" content="2017-09-11T00:00:00&#43;08:00">
  

  

  <title>Analyzing Wolf Warrior II Movie Comments using Python | Isaac Changhau</title>

</head>
<body id="top" data-spy="scroll" data-target="#toc" data-offset="71" >

<nav class="navbar navbar-default navbar-fixed-top" id="navbar-main">
  <div class="container">

    
    <div class="navbar-header">
      
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse"
              data-target=".navbar-collapse" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      
      <a class="navbar-brand" href="/">Isaac Changhau</a>
    </div>

    
    <div class="collapse navbar-collapse">

      
      
      <ul class="nav navbar-nav navbar-right">
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#about">
            
            <span>Home</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#projects">
            
            <span>Projects</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#posts">
            
            <span>Posts</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#tags">
            
            <span>Tags</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#publications">
            
            <span>Publications</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#achievements">
            
            <span>Achievements</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#contact">
            
            <span>Contact</span>
            
          </a>
        </li>

        
        
      

      
      </ul>

    </div>
  </div>
</nav>


<article class="article" itemscope itemtype="http://schema.org/Article">

  


  <div class="article-container">
    <h1 itemprop="name">Analyzing Wolf Warrior II Movie Comments using Python</h1>

    

<div class="article-metadata">

  <span class="article-date">
    
    <time datetime="2017-09-11 00:00:00 &#43;0800 &#43;08" itemprop="datePublished dateModified">
      Mon, Sep 11, 2017
    </time>
  </span>
  <span itemscope itemprop="author publisher" itemtype="http://schema.org/Person">
    <meta itemprop="name" content="Zhang Hao">
  </span>

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    4 min read
  </span>
  

  
  

  

  
  

  

</div>

    
    <div class="article-style" itemprop="articleBody">
      <p>想要分析“战狼II”的影评数据，首先需要获取这些数据，这里使用 Python 的 <code>requests</code> 包进行网页请求，并使用正则表达式匹配出我们需要的数据。首先使用Chrome打开豆瓣影评·战狼II的网页 (<a href="https://movie.douban.com/subject/26363254/comments?start=0" target="_blank">https://movie.douban.com/subject/26363254/comments?start=0</a>)，使用 Developer Tools 对当前页面做一个简单的了解和分析，如下图：
<img src="/img/python/wolf_warrior/comment-chrome.png" alt="Comment Loc" />
我们发现页面的所有评论、评论者、投票、评价等级等信息均存储在 <code>&lt;div class=&quot;comment-item&quot; ...&gt;</code> 标签下。而转向下一页面的链接信息存储在 <code>&lt;div id=&quot;paginator&quot;&gt;</code> 标签的 <code>&lt;a href=&quot;?start=26&amp;amp;limit=20&amp;amp;sort=new_score&amp;amp;status=P&quot; ... class=&quot;next&quot;&gt;...</code> 中。因此，可以针对这部分 HTML 标签创建相应的正则表达式来获取数据。简易的爬虫代码如下：</p>

<pre><code class="language-python">import requests 
import re
import pandas as pd
url_first = 'https://movie.douban.com/subject/26363254/comments?start=0'  # start page
head = {'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.79 Safari/537.36'}
cookies = {'cookie':'you own cookies}  #cookie of your account
html = requests.get(url_first, headers=head, cookies=cookies)  # get first page
re_page = re.compile(r'&lt;a href=&quot;(.*?)&amp;amp;.*?class=&quot;next&quot;&gt;') # next page
re_content = re.compile(r'&lt;span class=&quot;votes&quot;&gt;(.*?)&lt;/span&gt;.*?comment&quot;&gt;(.*?)&lt;/a&gt;.*?&lt;/span&gt;.*?&lt;span.*?class=&quot;&quot;&gt;(.*?)&lt;/a&gt;.*?&lt;span&gt;(.*?)&lt;/span&gt;.*?title=&quot;(.*?)&quot;&gt;&lt;/span&gt;.*?title=&quot;(.*?)&quot;&gt;.*?class=&quot;&quot;&gt; (.*?)\n', re.S)
while html.status_code==200:
    url_next = 'https://movie.douban.com/subject/26363254/comments' + re.findall(re_page, html.text)[0]
    data = re.findall(re_content, html.text)
    print(url_next)
    frame = pd.DataFrame(data)
    frame.to_csv('./data/comments.csv', header=False, index=False, mode='a+', encoding='utf-8')
    frame = []
    data = []
    html = requests.get(url_next, cookies=cookies, headers=head)
</code></pre>

<p>这里需要设置自己的 <code>User-Agent</code> 和 <code>cookie</code>，如果使用的是Chrome，可以直接进入 Developer Tools，在 <code>Network</code> 中找到当前页面，便能获得这些信息。以上，代码没有考虑豆瓣的验证码问题，因此爬取大概20000～30000条数据时便会报出 <code>443 Error</code>，由于验证码机器识别问题涉及到一些其他的领域，这里喔直接忽略这个问题，因为数据量不是很大，所以每次保存停止，只需要重新启动程序即可。这里爬取的数据为7类：<strong>赞同数</strong>，<strong>是否有用</strong>，<strong>用户名</strong>，<strong>是否看过</strong>，<strong>评分</strong>，<strong>日期</strong>以及<strong>评论内容</strong>。</p>

<p>完成19万+条数据爬取之后，由于存在一些格式错误等脏数据，仍需要做一些简单的数据清理，清理后的数据量为18万+。代码如下：</p>

<pre><code class="language-python">import re
import pandas as pd
reg_correct = re.compile(r'(.*),(.*),(.*),(.*),(.*),(.*),(.*)')
reg_dirty = re.compile(r'.*这条短评跟影片无关.*&lt;span class=&quot;&quot;votes&quot;&quot;&gt;(.*?)&lt;/span&gt;.*?class=&quot;&quot;j a_vote_comment&quot;&quot;&gt;(.*?)&lt;/a&gt;.*?class=&quot;&quot;&quot;&quot;&gt;(.*?)&lt;/a&gt;&lt;span&gt;(.*?)&lt;/span&gt;.*?title=&quot;&quot;(.*?)&quot;,(.*),(.*)')
data = []  # 格式化数据
with open('./data/comments.csv') as file:
    dirty_data = []  # 错误格式数据
    dirty_lines = ''
    flag = 0
    # load and clean data
    for line in file:
        arr = re.findall(reg_correct, line)
        if len(arr) == 0:
            dirty_lines = ''.join([dirty_lines, line.strip()])
            flag = 1
        else:
            value = (arr[0][0].replace('&quot;', ''), arr[0][1].replace('&quot;', ''), arr[0][2].replace('&quot;', ''), arr[0][3].replace('&quot;', ''), arr[0][4].replace('&quot;', ''), arr[0][5].replace('&quot;', ''), '`' + arr[0][6].replace('&quot;', '') + '`')
            data.append(value)
            if flag == 1:
                flag = 0
                dirty_data.append(dirty_lines)
                dirty_lines = ''
    # add cleaned data to data array
    for line in dirty_data:
        arr = re.findall(reg_dirty, line)
        if len(arr) != 0:
            value = (arr[0][0].replace('&quot;', ''), arr[0][1].replace('&quot;', ''), arr[0][2].replace('&quot;', ''), arr[0][3].replace('&quot;', ''), arr[0][4].replace('&quot;', ''), arr[0][5].replace('&quot;', ''), '`' + arr[0][6].replace('&quot;', '') + '`')
            data.append(value)
path = './data/comments_clean.csv'
pd.DataFrame(data).to_csv(path, header=False, index=False, encoding='utf-8')
print('Done...')
</code></pre>

<p>将数据保存为 <code>.csv</code> 文件，前5行数据如下：
<img src="/img/python/wolf_warrior/head.png" alt="Head" />
之后便是进行数据分析，在数据处理过程中发现，经过清理的数据中仍然有一些数据的格式错误，由于这部分数据量很小，所以直接将这部分数据删除：</p>

<pre><code class="language-python">import pandas as pd
# load data
column_names = ['Votes', 'Useful', 'User', 'Watched', 'Score', 'Date', 'Comment']
data = pd.read_csv('./data/comments_clean.csv', header=None, names=column_names, skipinitialspace = True, quotechar = '`')
# set value as string
data['Votes'] = data['Votes'].astype(str)
data['Useful'] = data['Useful'].astype(str)
data['User'] = data['User'].astype(str)
data['Watched'] = data['Watched'].astype(str)
data['Score'] = data['Score'].astype(str)
data['Date'] = data['Date'].astype(str)
data['Comment'] = data['Comment'].astype(str)
# clean up the data with error format
data = data[data['Score'].map(len) == 6]
data = data[data['Score'] != '看过']
data = data[data['Date'].map(len) == 19]
print('rows:', data.shape[0], ', columns: ', data.shape[1]) # count rows of total dataset
# out: ('rows:', 176875, ', columns: ', 7)
</code></pre>

<p>然后我们对不同评分的人数做一个简单的统计并作图：</p>

<pre><code class="language-python">import matplotlib.pyplot as plt
import numpy as np
print(data['Score'].value_counts())
index = np.arange(5)
score_counts = data['Score'].value_counts()
values = (score_counts[0], score_counts[1], score_counts[2], score_counts[4], score_counts[3])
bar_width = 0.35
plt.figure(figsize=(20, 10))
plt.bar(index, values, bar_width, alpha=0.6, color='rgbym')
plt.xlabel('Score', fontsize=16)  
plt.ylabel('Counts', fontsize=16)
plt.title('Comments Level', fontsize=18)  
plt.xticks(index, ('5-star', '4-star', '3-star', '2-star', '1-star'), fontsize=14, rotation=20)
plt.ylim(0, 90000)
plt.grid()
for idx, value in zip(index, values):
    plt.text(idx, value + 0.1, '%d' % value, ha='center', va='bottom', fontsize=14, color='black')
plt.show()
</code></pre>

<p>输出为：</p>

<pre><code class="language-bash">力荐    79361
推荐    47724
还行    29337
很差    10774
较差     9679
Name: Score, dtype: int64
</code></pre>

<p><img src="/img/python/wolf_warrior/stars.png" alt="Stars" />
从输出数据和上图中可以很明显的发现，对这部电影持好评 (推荐、力荐) 的人占大多数，部分人觉得还行，少数人评价差。</p>

<p>最后，我们对所有的评论内容进行云图展示，首先定义两个函数，一个用于对评论内容进行清理和分词，另一个进行云图生成。</p>

<p><strong>评论内容清理和分词</strong>：<br />
这里同样使用<a href="https://github.com/fxsjy/jieba" target="_blank">结巴分词</a>进行中文分词操作和 Python 内置正则表达式进行数据清洗操作。(注释掉的部分是移除中文停用词，为了加快运行速度，这里喔忽略了这个操作)</p>

<pre><code class="language-python">import re
import jieba
def segment_words(stars):
    comments = None
    if stars == 'all':
        comments = data['Comment']
    else:
        comments = data[data['Score'] == stars]['Comment']
    comments_list = []
    for comment in comments:
        comment = str(comment).strip().replace('span', '').replace('class', '').replace('emoji', '')
        comment = re.compile('1f\d+\w*|[&lt;&gt;/=]').sub('', comment)
        if (len(comment) &gt; 0):
            comments_list.append(comment)
    text = ''.join(comments_list)
    word_list = jieba.cut(text, cut_all=True)
    '''
    stopwords_list = []
    # load chinese stop words
    with open('./data/中文停用词表(1208个).txt') as file:
        for line in file:
            stopwords_list.append(line.strip())
    print(len(stopwords_list))
    with open('./data/停用词表.txt') as file:
        for line in file:
            line = line.strip()
            if line not in stopwords_list:
                stopwords_list.append(line)
    print(len(stopwords_list))
    # remove stop words from word_list
    word_list = [word for word in word_list if word not in stopwords_list]
    '''
    words = ' '.join(word_list)
    return words
</code></pre>

<p><strong>云图生成</strong>：<br />
云图生成使用 Python 的 <a href="https://github.com/amueller/word_cloud" target="_blank">WordCloud</a> 包和 <a href="https://python-pillow.org" target="_blank">Pillow</a> 图像处理包。代码如下：</p>

<pre><code class="language-python">from wordcloud import WordCloud, ImageColorGenerator
import PIL.Image as Image
def plot_word_cloud(words):
    coloring = np.array(Image.open('./data/chinese.jpg'))
    wc = WordCloud(background_color='white', max_words=2000, mask=coloring, max_font_size=60, random_state=42, 
                   font_path='./data/DroidSansFallbackFull.ttf', scale=2).generate(words)
    image_color = ImageColorGenerator(coloring)
    plt.figure(figsize=(32, 16))
    plt.imshow(wc.recolor(color_func=image_color))
    plt.imshow(wc)
    plt.axis('off')
    plt.show()
</code></pre>

<p>首先我们对所有的评论内容生成云图：</p>

<pre><code class="language-python">all_words = segment_words('all')
plot_word_cloud(all_words)
</code></pre>

<p><img src="/img/python/wolf_warrior/all.png" alt="All" />
然后分别对力荐、推荐，以及较差、很差生成评论云图，并进行比较：</p>

<pre><code class="language-python">five_start_words = segment_words('力荐')
plot_word_cloud(five_start_words)
four_start_words = segment_words('推荐')
plot_word_cloud(four_start_words)
</code></pre>

<p><img src="/img/python/wolf_warrior/4-5-star.png" alt="4-5" /></p>

<pre><code class="language-python">two_start_words = segment_words('较差')
plot_word_cloud(two_start_words)
one_start_words = segment_words('很差')
plot_word_cloud(one_start_words)
</code></pre>

<p><img src="/img/python/wolf_warrior/1-2-star.png" alt="1-2" />
以上便是影评数据的简单分析和展示，进一步的可以对影评数据进行更精确的清理和分词操作等，并且根据评分等级，可以用该数据为基础搭建一个用户正负情感的机器学习模型等。以后有时间，再对这些数据进行进一步的处理。</p>

<p>代码可在我的 GitHub Repository 中找到：<a href="https://github.com/IsaacChanghau/AmusingPythonCodes/tree/master/wolf_warriors_ii" target="_blank">AmusingPythonCodes/wolf_warriors_comments</a>。</p>

<p><strong>Reference</strong>:</p>

<ul>
<li><a href="https://zhuanlan.zhihu.com/p/28475619" target="_blank">&lt;&lt;战狼Ⅱ&gt;&gt;豆瓣十二万影评浅析</a></li>
</ul>

    </div>

    


<div class="article-tags">
  
  <a class="btn btn-primary btn-outline" href="/tags/natural-language-processing">natural-language-processing</a>
  
  <a class="btn btn-primary btn-outline" href="/tags/python">python</a>
  
</div>




    
    
    <div class="article-widget">
      <div class="hr-light"></div>
      <h3>Related</h3>
      <ul>
        
        <li><a href="/post/wechat_analysis/">Analyzing Your Friends Information in WeChat using Python</a></li>
        
        <li><a href="/project/primenet/">PrimeNet: Human-inspired Framework for Commonsense Knowledge Representation and Reasoning</a></li>
        
        <li><a href="/post/beam_search/">Beam Search Algorithms in Sequence to Sequence</a></li>
        
        <li><a href="/post/seq2seq_conversation/">Seq2Seq Learning and Neural Conversational Model</a></li>
        
        <li><a href="/post/neural_responding_machine/">Neural Responding Machine for Short-Text Conversation -- Summary</a></li>
        
      </ul>
    </div>
    

    

    


  </div>
</article>

<footer class="site-footer">
  <div class="container">
    <p class="powered-by">

      &copy; 2017-2018 &middot; 

      <strong>Isaac Changhau (Zhang Hao)</strong>
      

      <span class="pull-right" aria-hidden="true">
        <a href="#" id="back_to_top">
          <span class="button_icon">
            <i class="fa fa-chevron-up fa-2x"></i>
          </span>
        </a>
      </span>

    </p>
  </div>
</footer>


<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <button type="button" class="close btn-large" data-dismiss="modal">&times;</button>
        <h4 class="modal-title">Cite</h4>
      </div>
      <div>
        <pre><code class="modal-body tex"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-primary btn-outline js-copy-cite" href="#" target="_blank">
          <i class="fa fa-copy"></i> Copy
        </a>
        <a class="btn btn-primary btn-outline js-download-cite" href="#" target="_blank">
          <i class="fa fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

    

    
    

    

    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.2.1/jquery.min.js" integrity="sha512-3P8rXCuGJdNZOnUx/03c1jOTnMn3rP63nBip5gOP2qmUh5YAdVAvFZ1E+QLZZbC1rtMrQb+mah3AfYW11RUrWA==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.3/imagesloaded.pkgd.min.js" integrity="sha512-umsR78NN0D23AzgoZ11K7raBD+R6hqKojyBZs1w8WvYlsI+QuKRGBx3LFCwhatzBunCjDuJpDHwxD13sLMbpRA==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha512-iztkobsvnjKfAtTNdHkGVjAYTrrtlC7mGp/54c40wowO7LhURYl3gVzzcEqGl/qKXQltJ2HwMrdLcNUdo+N/RQ==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.4/isotope.pkgd.min.js" integrity="sha512-VDBOIlDbuC4VWxGJNmuFRQ0Li0SKkDpmGyuhAG5LTDLd/dJ/S0WMVxriR2Y+CyPL5gzjpN4f/6iqWVBJlht0tQ==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>
    
    
    <script src="/js/hugo-academic.js"></script>
    

    
    
      
      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>
      

      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/java.min.js"></script>
      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/python.min.js"></script>
      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/scala.min.js"></script>
      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/javascript.min.js"></script>
      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/c.min.js"></script>
      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/html.min.js"></script>
      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/bash.min.js"></script>
      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/xml.min.js"></script>
      

      

      <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({ 
          tex2jax: { 
            inlineMath: [['$','$'], ['\\(','\\)']] 
          } 
        });
    </script>
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_CHTML" integrity="sha512-xAWI9i8WMRLdgksuhaMCYMTw9D+MEc2cYVBApWwGRJ0cdcywTjMovOfJnlGt9LlEQj6QzyMzpIZLMYujetPcQg==" crossorigin="anonymous"></script>
    
    
    

  </body>
</html>

